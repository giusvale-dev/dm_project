\documentclass[conference]{IEEEtran}

\usepackage{graphicx} % For including images
\usepackage{amsmath} % For mathematical symbols and equations
\usepackage{hyperref} % For hyperlinks
\usepackage{caption}
\usepackage{amsfonts} % For math fonts and symbols
\usepackage{booktabs} % For better tables
\usepackage{listings} % For code listings
\usepackage{multirow} % For multi-row cells in tables
\usepackage{float} % For float image

\begin{document}
	
	\title{Data Management \\ Project of a Data Warehouse System for Analyzing Meteorite Landings by NASA}
	
	\author{
		\IEEEauthorblockN{Giuseppe Valente - Natalia Maria Mucha}
		\IEEEauthorblockA{
			Engineering in Computer Science \\
			Sapienza University of Rome \\
		}
	}
	\maketitle
	
	\begin{abstract}
			This project focuses on designing and developing a data warehouse (DWH) system to integrate and analyze meteorite landing data from NASA. The objective is to demonstrate the design and implementation of a data warehouse using a relational database (PostgreSQL), starting from the datasets.
	\end{abstract}
	
	\section{Introduction}
	
	This project aims to design and develop a DWH system specifically to integrate and analyze meteorite landing data using NASA's Meteorite Landings dataset. The first section focuses on both the design and development of the DWH, beginning with the Dimensional Fact Model (DFM), followed by the implementation of the Star Schema and the database itself. The second section is dedicated to the system architecture, detailing the components used, including the Extraction, Transformation, and Loading (ETL) processes, and how these tools are implemented. Docker containers are utilized to manage the DWH system, providing portability and simplicity. The final section contains the Git repository with the source code used for this project.
	
	\section{Data Warehouse}
	A DWH is a system used for reporting and data analysis. It serves as a central repository of integrated data from one or more sources (datasets or data sources). It stores both current and historical data in a single location, which is used for generating reports. This is beneficial for companies as it enables them to query and draw insights from their data, facilitating informed decision-making.

	The data stored in the DWH is uploaded from operational systems but first undergoes a process to ensure data quality before being used in DWH analysis (ETL process).

	The DWH employs a multidimensional model represented in \textbf{facts} that are subjects of analysis and represented as cubes, where:
	\begin{itemize}
		\item Each cell contains numerical \textbf{measures} (quantifying the fact from one perspective).
		\item Each axis represents a \textbf{dimension} of interest for analysis.
		\item Each dimension can be associated with a \textbf{hierarchy of dimensional attributes} used to aggregate data stored in the cubes.
	\end{itemize}

	To retrieve information from the DWH, four methodologies are used:
	\begin{itemize}
		\item Reports
		\item Dashboards
		\item Data mining
		\item OLAP
	\end{itemize}
	 
	\section{Requirements}
	\label{sec:requirements}
	We are interested in analyzing meteorite landings; for this reason, we use the following information:
	\begin{itemize}
		\item \textbf{Measure:} Meteorite mass in grams
		\item \textbf{Dimensions:} Time, Location, Meteorite Classification
	\end{itemize}
	\section{Dimensional Fact Model (DFM)}
	Starting from section\ref{sec:requirements} we designed the DFM model shown in Figure \ref{fig:Meteorite Landings System Architecture}. \\This figure illustrates the use of dimensional hierarchies for all dimensions, as well as optional dimension values.
	\begin{figure}[htpb]
		\centering
		\includegraphics[width=\columnwidth]{images/dfm_schema.png}
		\caption{Meteorite Landings System Architecture}
		\label{fig:Meteorite Landings System Architecture}
	\end{figure}
	\section{Star Schema}
	A multidimensional structure can be represented using two distinct logical models:
	\begin{itemize}
		\item MOLAP (Multidimensional On-Line Analytical Processing)
		\item ROLAP (Relational On-Line Analytical Processing)
	\end{itemize}
	For our purpose we used the ROLAP model with the star schema.\\ Figure \ref{fig:Meteorite Landings Star Schema} describe the translation from the DFM to the Start Schema using the literature:
	\begin{figure}[htpb]
		\centering
		\includegraphics[width=\columnwidth]{images/star_schema.png}
		\caption{Meteorite Landings Star Schema}
		\label{fig:Meteorite Landings Star Schema}
	\end{figure}
	
	\section{System Architecture}
	The DWH architecture generally comprises the following components:
	\begin{itemize}
		\item \textbf{Datasets:} Collections of structured data organized to support reporting, analysis, and decision-making. These datasets are derived from various sources and are typically arranged to optimize querying and analysis.
		\item \textbf{ETL:} Stands for Extract, Transform, Load. It is a process used in data warehousing to move data from source systems to the data warehouse.
		\item \textbf{Primary DWH:} Refers to the central repository where an organization consolidates, stores, and manages its key business data for analysis and reporting. It is designed to support decision-making by providing a comprehensive view of data from various sources.
		\item \textbf{Data Mart:} A specialized subset of a DWH, designed to focus on a specific business area, department, or function. It is essentially a smaller, more focused version of a DWH that serves the needs of particular users or business units.
		\item \textbf{Reconciled Data (three-layer architecture only):} Refers to data that has been verified, adjusted, and aligned to ensure consistency, accuracy, and completeness across various sources or systems. The process of reconciling data involves comparing and aligning data from different sources to resolve discrepancies and ensure that the data is accurate and reliable.
	\end{itemize}
	
	The components are organized in either a two-layer or a three-layer architecture:	
	\subsection{Two-Layer Architecture (2LA)}
	The 2LA consists of two main components: the data sources and the DWH. In this architecture, data marts are considered part of the "presentation layer." This architecture is particularly useful for mid-sized to large organizations.
	\subsection{Three-Layer Architecture (3LA)}
	In this architecture, there is an additional layer: the reconciled data layer. This layer creates a common reference data model for the entire enterprise. It also clearly separates the issues of source data extraction and integration from those of DWH population. However, the reconciled data approach can lead to increased replication of operational source data, and the design process can be more complex.
			
	\subsection{Meteorite Landings - Architecture}
	For our purposes, we have opted to use the two-layer architecture (2LA) because we have a limited number of data sources, the ETL process is relatively simple, and it can be managed on the fly. However, in a real-world scenario, it would be advantageous to use a three-layer architecture (3LA). This architecture allows for the separation of Data Staging from Data Loading through the Reconciled Data Layer. Such separation facilitates the design of simpler and more efficient ETL tools, each focused on a specific task (e.g., \texttt{extract.py}, \texttt{transform.py}, \texttt{load.py}). Additionally, containerized technologies like Kubernetes or Docker can enable horizontal scaling of these tools, allowing the system to handle increased computational loads or growth in data sources more effectively.\\For simplicity, we use Docker to distribute the application in the most straightforward manner possible, but this does not imply that the application is scalable.\\As shown in Figure~\ref{fig:Meteorite Landings System Architecture}, our architecture includes the following components:
	\begin{itemize}
		\item \textbf{Datasets: (Meteorite Landings, Socrata Location)}
		\item \textbf{ETL: (meteorite\_landings\_etl)}
		\item \textbf{Primary DWH: PostgreSQL}  
	\end{itemize}
	\begin{figure}[htpb]
		\centering
		\includegraphics[width=\columnwidth]{images/system_architecture.png}
		\caption{Meteorite Landings System Architecture}
		\label{fig:Meteorite Landings System Architecture}
	\end{figure}
	
	\section{Source Layer}
	
	\subsection{Meteorite Landings Dataset}
	\label{subsec:meteorite landings data set}
	This comprehensive dataset from The Meteoritical Society contains information on all known meteorite landings. The Fusion Table was compiled by Javier de la Torre, and we have also provided an XLS file containing data on 34,513 meteorites. For additional details, visit \href{https://data.nasa.gov/Space-Science/Meteorite-Landings/gh4g-9sfh/about_data}{NASA's Open Data Portal}
		
	\subsection{Socrata Location}
	\label{subsec:socrata_dataset}
	The dataset is used to convert coordinate points from latitude and longitude to a human-readable format. For more information, see 
	\href{https://dev.socrata.com/docs/datatypes/location.html#}{Tyler Technologies - Socdata}
				
	\section{ETL tools}
	The ETL process is carried out using \texttt{meteorite\_landings\_etl}.\\ This software, developed in Python, includes the following modules:
	\begin{itemize}
		\item \textbf{extract} - Reads data from the dataset described in section \ref{subsec:meteorite landings data set}
		\item \textbf{transform} - Processes the data rows obtained from the Extract module. It is responsible for cleaning and transforming the data, using additional datasets and metadata information.
		\item \textbf{load} - Takes the cleaned and transformed data from the Transform module and loads it into the DWH database.
	\end{itemize}
	The ETL sequence diagram is shown in the figure \ref{fig:ETL Sequence Diagram}:
	\begin{figure}[htpb]
		\centering
		\includegraphics[width=\columnwidth]{images/sequence_diagram_etl.png}
		\caption{ETL Sequence Diagram}
		\label{fig:ETL Sequence Diagram}
	\end{figure}
	
	
	Details of these modules are described in the following sections.
	\subsection{Extract}
    Extraction is the process that allows us to obtain data from sources, and we know that this operation can be either static (generally used when the DWH needs to be populated for the first time) or incremental (used to update the DWH regularly). Since our datasets are not updated at regular intervals, we have decided to implement only static extraction. If an update is required, we will back up the previous DWH and then populate a new DWH system.\\ The extractor has 2 mainly problems to solve:
    \begin{itemize}
    	\item Navigate through the API pagination, to retrieve all data
    	\item Produce a rough parsed object contained all data read
    \end{itemize}
    
     The NASA dataset contains the information shown in the table \ref{tab:nasa_dataset}:
    \begin{table}[httb]
    	\centering
    	\caption{Meteorite Landings dataset}
    	\begin{tabular}{|p{1cm}|p{4cm}|p{1cm}|p{1cm}|}
    		\hline
    		\textbf{Name} & \textbf{Description} & \textbf{Field name} & \textbf{Datatype} \\ \hline
    		name & Meteorite Name & name & Text \\ \hline
    		id   & Meteorite Identifier  & id & Text \\ \hline
    		nametype & Relict meteorite or valid & nametype & Text \\ \hline
    		recclass & Meteorite Classification & recclass & Text \\ \hline
    		mass & Meteorite Mass (grams) & mass & Number \\ \hline
    		fall & Meteorite Fall on the earth or not & fall & Text \\ \hline
    		year & Event data (FLoating timestamp) & year & Floating timestamp \\ \hline
    		reclat & Latitude of the event & reclat & Text \\ \hline
    		reclong & Longitude of the event & reclong & Text \\ \hline
    	\end{tabular}
    	\label{tab:nasa_dataset}
    \end{table}
	
	To map the retrieved information we used the \texttt{MeteoriteLandingRough} object as shown in the Figure \ref{fig:MeteoriteLandingRough}.
	\begin{figure}[htpb]
		\centering
		\includegraphics[width=\columnwidth]{images/meteorite_landing_rough_obj.png}
		\caption{Meteorite Landing Rough Object}
		\label{fig:MeteoriteLandingRough}
	\end{figure}
	
	\subsection{Transform}
	This task solve the following problems:
	\begin{itemize}
		\item Remove all null values
		\item Convert the time in according to the dimension date
		\item Convert the latitude/longitude in according to the dimension location through the dataset in section \ref{subsec:socrata_dataset}
	\end{itemize}
	After this process we have the list of the transformed data, where it is represented through the object shown in figure \ref{}
	
	\subsection{Load}
	The transformed data is loaded into the relational database using SQLAlchemy in Python, ensuring that all datasets are correctly integrated for analysis.
	
	\section{Data warehouse Layer}
	
	\subsection{Dimensions Fact Model (DFM)}
	
	\subsection{Relational Database realization}

	\section{Conclusion}
	
	\section{Reference}
	\begin{itemize}
		\item \href{https://www.diag.uniroma1.it/~lenzerin/index.html/?q=node/53}{Data Management Course}
		\item \href{https://web.pdx.edu/~ruzickaa/meteorites/papers/WeisbergEtal2006-classification.pdf}{Weisberg et al. (2006) Systematics and Evaluation of Meteorite Classification. In, Meteorites and the Early Solar System II, 19-52 (D.S. Lauretta and H.Y. McSween, Eds.), Univ. Arizona press}
		\item \href{https://data.nasa.gov/Space-Science/Meteorite-Landings/gh4g-9sfh/about_data}{NASA's Open Data Portal}
		\item \href{https://dev.socrata.com/docs/datatypes/location.html#}{Tyler Technologies - Socdata}
	\end{itemize}
	
	
	
	
	
\end{document}
